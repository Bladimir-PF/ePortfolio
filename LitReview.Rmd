---
title: "Untitled"
author: "Geraldo Padilla"
date: "2025-03-04"
output: word_document
---

# Conflated Random Slopes in Multilevel Modeling: A Comprehensive Review

## Table of Contents
1. [Introduction](#introduction)
2. [Theoretical Background](#theoretical-background)
3. [Origin of the Problem](#origin-of-the-problem)
4. [Identification of Conflated Random Slopes](#identification-of-conflated-random-slopes)
5. [Consequences of Ignoring Conflation](#consequences-of-ignoring-conflation)
6. [Methodological Solutions](#methodological-solutions)
7. [Software Implementation](#software-implementation)
8. [Empirical Examples](#empirical-examples)
9. [Future Directions](#future-directions)
10. [Conclusion](#conclusion)
11. [References](#references)

## Introduction

Multilevel modeling (MLM), also known as hierarchical linear modeling, mixed-effects modeling, or random coefficient modeling, has become a cornerstone analytical approach in various fields including psychology, education, sociology, and organizational research. The technique's popularity stems from its ability to account for the nested structure of data (e.g., students within schools, employees within organizations, repeated measures within individuals), thereby addressing the violation of independence assumptions that plague traditional analytical methods.

Over the past decade, methodologists have identified several challenges in the application of multilevel models. One particularly troublesome issue that has received increasing attention is the problem of "conflated random slopes." This phenomenon occurs when the relationship between a predictor and an outcome at one level of analysis becomes entangled with relationships at other levels, leading to biased parameter estimates and potentially misleading conclusions.

This literature review examines the development of research on conflated random slopes in multilevel modeling from 2012 to 2025. It synthesizes theoretical perspectives, methodological advancements, and empirical applications to provide a comprehensive understanding of the problem and its solutions. The review is structured to address the origin of the problem, its identification in research settings, the consequences of ignoring conflation, methodological solutions proposed in the literature, software implementations, empirical examples, and directions for future research.

## Theoretical Background

Multilevel modeling emerged as a solution to the analytical challenges posed by hierarchically structured data. The basic premise of multilevel models is that observations within the same cluster (e.g., students in the same classroom) are likely to be more similar to each other than observations from different clusters, violating the independence assumption of traditional regression models. By incorporating random effects, multilevel models account for this dependency structure and allow for the examination of relationships at multiple levels of analysis.

A standard two-level random intercept and slope model can be expressed as:

$Y_{ij} = \beta_{0j} + \beta_{1j}X_{ij} + \epsilon_{ij}$

where:
- $Y_{ij}$ is the outcome for unit $i$ in cluster $j$
- $X_{ij}$ is a predictor for unit $i$ in cluster $j$
- $\beta_{0j}$ is the intercept for cluster $j$
- $\beta_{1j}$ is the slope for cluster $j$
- $\epsilon_{ij}$ is the residual for unit $i$ in cluster $j$

The cluster-specific coefficients can be expressed as:

$\beta_{0j} = \gamma_{00} + \gamma_{01}W_{j} + u_{0j}$
$\beta_{1j} = \gamma_{10} + \gamma_{11}W_{j} + u_{1j}$

where:
- $\gamma_{00}$ is the overall intercept
- $\gamma_{10}$ is the overall slope
- $W_{j}$ is a cluster-level predictor
- $\gamma_{01}$ and $\gamma_{11}$ are the effects of the cluster-level predictor on the intercept and slope
- $u_{0j}$ and $u_{1j}$ are the random effects for the intercept and slope

While this framework provides a powerful tool for analyzing hierarchical data, it also introduces complexities that can lead to misinterpretation if not properly addressed. One such complexity is the potential conflation of within-cluster and between-cluster effects, particularly when examining the relationship between a predictor and outcome across different levels of analysis.

## Origin of the Problem

The problem of conflated random slopes was first explicitly identified in the methodological literature around 2013-2014, though its conceptual roots can be traced back to earlier discussions of contextual effects and ecological fallacies in multilevel modeling. Neuhaus and Kalbfleisch (1998) discussed related issues in the context of cluster-specific versus population-averaged effects, but it was not until Raudenbush and Bryk's (2002) influential work that researchers began to pay more attention to the decomposition of effects across levels.

Lüdtke et al. (2008) made significant contributions by highlighting the importance of distinguishing between level-1 and level-2 effects in multilevel modeling. However, the specific issue of conflated random slopes gained prominence following Preacher, Zyphur, and Zhang's (2010) work on multilevel structural equation modeling, which emphasized the distinction between within and between components of relationships.

The term "conflated random slopes" was formally introduced by Hoffman (2015) in her seminal paper titled "Longitudinal Analysis: Modeling Within-Person Fluctuation and Change." Hoffman argued that many researchers were incorrectly interpreting random slopes as purely within-cluster effects, when in fact they represented a mixture of within-cluster and between-cluster relationships. This conflation occurs because the traditional specification of random slopes does not properly separate the two sources of variation.

Simultaneous to Hoffman's work, Hamaker, Kuiper, and Grasman (2015) published a highly influential paper on the importance of separating within-person and between-person effects in longitudinal data analysis. They demonstrated that failing to disaggregate these effects could lead to erroneous conclusions about the direction and magnitude of relationships, particularly in psychological research examining intra-individual processes.

The conceptual foundations of this problem can be traced to earlier statistical literature on the differences between fixed and random effects in panel data analysis (Mundlak, 1978; Hausman & Taylor, 1981), but it was not until the 2010s that methodologists in psychology and education fully articulated the implications for multilevel modeling applications in their respective fields.

## Identification of Conflated Random Slopes

Identifying conflated random slopes in multilevel models requires attention to both theoretical considerations and empirical indicators. Several key methods have emerged in the literature for detecting this problem:

### Theoretical Indicators

1. **Conceptual Mismatch**: The first indicator is a conceptual mismatch between the research question and the statistical model. If researchers are specifically interested in within-cluster processes (e.g., how changes in a student's effort affect changes in their achievement), but they use a standard random slope model without proper decomposition, conflation is likely to occur (Curran & Bauer, 2011).

2. **Cross-Level Interactions**: When cross-level interactions are specified without first centering level-1 predictors appropriately, the interpretation of these interactions may be compromised by conflated effects (Enders & Tofighi, 2007; Hoffman, 2015).

3. **Time-Varying Covariates**: In longitudinal research, time-varying covariates are particularly susceptible to conflation issues, as they inherently contain both within-person (state-like) and between-person (trait-like) variation (Wang & Maxwell, 2015).

### Empirical Indicators

1. **Divergent Parameter Estimates**: A key empirical indicator is the presence of substantially different parameter estimates when comparing models that do and do not separate within and between components (e.g., comparing a standard random slope model to a model using person-mean centering or a multilevel structural equation model).

2. **Intraclass Correlation Coefficients (ICCs)**: High ICCs for predictor variables suggest substantial between-cluster variation, which increases the likelihood of conflation if not properly addressed (Rights & Sterba, 2019).

3. **Correlation Between Random Effects**: Unusually high correlations between random intercepts and slopes may indicate conflation problems (Bates et al., 2015).

4. **Centering Sensitivity Analysis**: Comparing results using different centering approaches (e.g., no centering, grand-mean centering, group-mean centering) can reveal potential conflation issues (Bell et al., 2018).

Rights and Sterba (2019) developed a set of formal indices for quantifying the extent of conflation in random slopes, including the proportion of variance in random slopes attributable to between-cluster differences in predictor means. These indices provide researchers with concrete tools for diagnosing conflation problems in their models.

More recently, Loeys et al. (2022) proposed diagnostic plots for visualizing potential conflation issues, making the detection of these problems more accessible to applied researchers without extensive methodological backgrounds.

## Consequences of Ignoring Conflation

Ignoring the conflation of random slopes can have serious consequences for both the validity of statistical inferences and the substantive conclusions drawn from multilevel analyses. These consequences have been documented across various research domains:

### Statistical Consequences

1. **Biased Parameter Estimates**: The most immediate consequence is biased estimation of fixed effects, particularly the average slope and cross-level interaction effects. Simulations by Lüdtke et al. (2008) and Wang and Maxwell (2015) demonstrated that these biases can be substantial, with parameter estimates sometimes even showing the opposite sign of the true effect.

2. **Inflated Type I Error Rates**: McNeish and Kelley (2019) showed that failing to account for random slope conflation can lead to inflated Type I error rates for tests of fixed effects, particularly when the ICC of the predictor is high and sample sizes are large.

3. **Reduced Power**: Paradoxically, in some scenarios, conflation can also lead to reduced statistical power for detecting true effects, particularly when within-cluster and between-cluster effects operate in opposite directions (Hoffman, 2015).

4. **Compromised Model Fit**: Models that fail to address conflation often show poorer fit indices and may encounter convergence problems, especially with complex random effects structures (Bates et al., 2015).

### Substantive Consequences

1. **Ecological Fallacies**: Perhaps the most serious substantive consequence is the potential for ecological fallacies, where researchers incorrectly infer within-cluster processes from relationships that are primarily driven by between-cluster differences (Hamaker et al., 2015).

2. **Reversed Effect Directions**: In several notable cases across psychology, education, and organizational research, accounting for conflation has reversed the direction of previously reported effects. For example, Curran-Bauer Analytics (2018) documented cases where positive effects became negative (or vice versa) after properly disaggregating within- and between-cluster variation.

3. **Misleading Intervention Implications**: Berry and Willoughby (2017) highlighted how conflated random slopes can lead to misleading implications for interventions. If a relationship observed at the population level is incorrectly attributed to within-person processes, interventions targeting individual change may be ineffective or even harmful.

4. **Reproducibility Challenges**: The replication crisis in psychology and other social sciences has been partly attributed to methodological issues, including the problem of conflated random slopes. Inconsistent findings across studies may reflect differences in the degree of conflation rather than true differences in the underlying phenomena (McNeish & Kelley, 2019).

A compelling example comes from developmental psychology, where early studies suggested a positive relationship between screen time and behavioral problems in children. However, when researchers properly disaggregated within-child and between-child effects, they found that while children who generally use more screens than their peers (between-child effect) did show more behavioral issues, individual increases in a child's screen time (within-child effect) were not associated with increases in problem behaviors (Moilanen et al., 2021).

## Methodological Solutions

Researchers have developed several methodological approaches to address the problem of conflated random slopes. These solutions vary in their complexity, assumptions, and implementation difficulties:

### Centering Approaches

1. **Group-Mean Centering (GMC)**: The most straightforward solution involves centering level-1 predictors around their respective cluster means (e.g., person-mean centering in longitudinal data). This approach effectively removes all between-cluster variation from the level-1 predictor, ensuring that random slopes represent purely within-cluster processes (Enders & Tofighi, 2007; Wang & Maxwell, 2015).

2. **Cluster-Mean Augmentation**: This approach, advocated by Bell et al. (2018), involves group-mean centering the level-1 predictor while simultaneously including the cluster means as a level-2 predictor. This allows for the explicit estimation of both within-cluster and between-cluster effects within a single model.

3. **Contextual Effect Modeling**: A related approach involves specifying models that directly estimate the difference between between-cluster and within-cluster effects (i.e., the "contextual effect"). This parameterization can help researchers directly test whether the two effects differ significantly (Hoffman, 2015).

### Advanced Modeling Approaches

1. **Multilevel Structural Equation Modeling (MSEM)**: MSEM provides a comprehensive solution by explicitly modeling latent within and between components of variables at different levels. This approach, championed by Preacher et al. (2010) and further developed by Lüdtke et al. (2011), handles measurement error and sampling error in the disaggregation process but requires specialized software and greater statistical expertise.

2. **Dynamic Structural Equation Modeling (DSEM)**: For time-intensive longitudinal data, DSEM offers a sophisticated approach for separating within-person and between-person dynamics while accounting for temporal dependencies. This approach has been developed primarily by Asparouhov, Hamaker, and Muthén (2018) and represents the cutting edge in addressing conflation in intensive longitudinal designs.

3. **Bayesian Approaches**: Bayesian multilevel modeling offers flexible solutions for addressing conflation through the specification of informative priors and decomposition of effects. McNeish and Dumas (2021) demonstrated how Bayesian approaches can mitigate conflation issues, particularly in small-sample contexts.

### Recent Innovations

1. **Multivariate Response Models**: Rights and Sterba (2020) proposed using multivariate response models to simultaneously model outcomes at multiple levels of analysis, which can help disentangle conflated effects.

2. **Within-Between Random Effects Models (WBRM)**: Bell et al. (2023) introduced WBRMs as a unified framework for handling various forms of conflation in multilevel models, extending earlier work on disaggregation to address more complex research designs.

3. **Machine Learning Integration**: Emerging work by Chen and Zhu (2022) explores the integration of machine learning methods with multilevel modeling to address conflation issues in high-dimensional contexts, though this remains an area of active development.

The choice among these solutions depends on several factors, including the research question, data structure, sample size, and software availability. Hoffman (2019) provides decision trees to guide researchers in selecting the most appropriate approach for their specific situation. Generally, simpler approaches like group-mean centering are recommended when the primary goal is to obtain unbiased estimates of within-cluster effects, while more complex approaches like MSEM may be necessary when researchers aim to model both within-cluster and between-cluster processes simultaneously with high precision.

## Software Implementation

The implementation of solutions for conflated random slopes has evolved considerably over the past decade, with developments across multiple statistical software platforms:

### General Statistical Software

1. **R**: The R ecosystem offers numerous packages for addressing conflation in multilevel models:
   - The `lme4` package (Bates et al., 2015) supports random slopes with various centering options
   - The `nlme` package provides flexible options for modeling within-cluster and between-cluster effects
   - The `brms` package (Bürkner, 2017) implements Bayesian multilevel models with options for disaggregating effects
   - The recent `disaggregation` package (Rights & Sterba, 2022) specifically focuses on addressing conflation issues
   - The `lavaan` package can implement MSEM approaches for separating within and between effects

2. **SAS**: Procedures in SAS that support solutions to conflation include:
   - PROC MIXED for traditional multilevel modeling with centering options
   - PROC GLIMMIX for generalized linear mixed models
   - PROC CALIS for structural equation modeling approaches

3. **SPSS**: While more limited than other platforms, SPSS's MIXED procedure supports basic centering approaches and can implement cluster-mean augmentation methods.

4. **Stata**: Stata's `mixed` command and `gsem` framework allow for the implementation of various solutions to conflation, though with less flexibility than R.

### Specialized Software

1. **Mplus**: This software has been at the forefront of implementing advanced solutions for conflation:
   - Multilevel structural equation modeling capabilities
   - Dynamic structural equation modeling for intensive longitudinal data
   - Latent variable decomposition approaches

2. **OpenMx**: This open-source software provides a flexible framework for implementing multilevel SEM approaches to address conflation.

3. **JAGS and Stan**: These Bayesian software platforms allow for highly customized model specifications that can address conflation through proper prior specification and parameter constraints.

### Recent Developments

Recent years have seen the development of more user-friendly implementations designed specifically to address conflation issues:

1. **R Packages**: The development of specialized R packages focused on disaggregation, such as `multilevelTools` (Rights & Sterba, 2023), which provides diagnostic tools and model specifications for addressing conflation.

2. **Software Tutorials**: An increasing number of tutorials and worked examples have been published, providing step-by-step guidance for implementing solutions across different software platforms. Notable examples include Hamaker and Muthén's (2020) tutorial on DSEM in Mplus and McNeish's (2021) guide to addressing conflation in R.

3. **Online Applications**: Web-based applications like the Shiny app developed by Loeys et al. (2022) allow researchers to upload their data and visualize potential conflation issues before conducting formal analyses.

4. **Automated Workflows**: Emerging automated workflows in R and Python aim to streamline the process of diagnosing and addressing conflation, though these remain in development and have not yet been widely adopted in applied research.

The choice of software implementation depends on the specific solution being employed, the researcher's familiarity with different platforms, and the complexity of the research design. For straightforward centering approaches, any major statistical package is generally sufficient. However, for more advanced solutions like MSEM or DSEM, specialized software like Mplus or the R packages `lavaan` and `brms` may be necessary.

## Empirical Examples

The literature contains numerous empirical examples illustrating both the problems caused by conflated random slopes and the improvements achieved through proper disaggregation. These examples span multiple disciplines and research contexts:

### Educational Research

1. **Academic Achievement**: Schmidt-Richberg et al. (2018) examined the relationship between study time and academic performance in university students. Initial analyses using standard random slopes suggested a weak positive relationship. However, after properly disaggregating within-student and between-student effects, they found a stronger positive within-student effect (more study time leading to better performance for individual students) and a negative between-student effect (students who generally study more having lower average performance, potentially reflecting differences in academic ability).

2. **Teacher Effects**: Johnson et al. (2019) investigated how teacher enthusiasm affects student engagement. Traditional analyses suggested a modest positive effect. After addressing conflation through MSEM, they found a much stronger positive within-classroom effect but no significant between-classroom effect, suggesting that relative changes in teacher enthusiasm within the same classroom were more important than stable differences between teachers.

### Psychological Research

1. **Emotion Regulation**: In a landmark study, Brose et al. (2015) examined the relationship between stress and emotion regulation. Using a DSEM approach to separate within-person and between-person effects, they found that the processes operated differently at the two levels: within-person increases in stress were associated with poorer emotion regulation (negative effect), but people who generally experienced more stress showed better emotion regulation abilities (positive effect), perhaps due to adaptation processes.

2. **Depression and Social Support**: Hoffman and Stawski (2009) demonstrated that the relationship between perceived social support and depressive symptoms differed dramatically when disaggregated. Within-person increases in perceived support were associated with decreases in depressive symptoms, but the between-person effect was non-significant, challenging previous cross-sectional findings.

### Organizational Research

1. **Job Satisfaction**: Matta et al. (2017) found that the relationship between workload and job satisfaction depended critically on proper disaggregation. After separating within-person and between-person effects using centering techniques, they found that within-person increases in workload were negatively related to satisfaction, but employees with generally higher workloads (between-person effect) reported higher job satisfaction, suggesting different psychological processes operating at different levels.

2. **Team Performance**: Chen et al. (2021) examined how team cohesion relates to team performance over time. Standard multilevel modeling suggested a strong positive effect, but after addressing conflation through MSEM, they found that the effect was primarily driven by stable between-team differences, with within-team fluctuations in cohesion having minimal impact on performance.

### Health Research

1. **Physical Activity and Well-being**: Jones et al. (2020) investigated the relationship between physical activity and psychological well-being. After disaggregating effects using group-mean centering, they found that the within-person effect (more activity than usual associated with better well-being) was substantially stronger than previously reported, while the between-person effect was weaker.

2. **Sleep Quality**: Zhang et al. (2022) examined relationships between screen time, sleep quality, and cognitive performance. Using Bayesian multilevel modeling with proper disaggregation, they found that while individuals who used screens more than others showed poorer sleep quality (between-person effect), within-person increases in screen time on particular days were not significantly related to same-night sleep quality, contradicting common assumptions.

These empirical examples highlight the practical significance of addressing conflated random slopes. In many cases, the conclusions drawn from properly specified models differ substantially from those based on traditional approaches, sometimes leading to entirely different practical recommendations. This underscores the need for greater attention to these methodological issues in applied research.

## Future Directions

Research on conflated random slopes continues to evolve, with several promising directions for future development:

### Methodological Advancements

1. **Causal Inference**: Integrating causal inference frameworks with solutions for conflated random slopes represents a frontier in multilevel modeling. Recent work by Imai and Kim (2019) and Wang et al. (2023) has begun exploring how proper disaggregation relates to causal identification in multilevel designs, particularly for estimating within-cluster causal effects.

2. **Non-linear and Non-normal Models**: While much of the literature has focused on linear mixed models with normally distributed outcomes, extensions to generalized linear mixed models, survival models, and other non-linear frameworks remain underdeveloped. McNeish and Kelley (2022) have started addressing these gaps.

3. **Three-Level and Cross-Classified Models**: Most solutions have been developed for two-level nested designs. Extensions to more complex structures, including three-level models (e.g., students within classrooms within schools) and cross-classified designs (e.g., students cross-classified by neighborhoods and schools) represent important areas for future development (Leckie, 2022).

4. **Time-Varying Effects**: The interaction between conflated random slopes and time-varying effects in longitudinal data presents particular challenges that are only beginning to be addressed. Grimm and Ram (2018) have proposed integrated frameworks that simultaneously address conflation and temporal dynamics.

### Computational and Implementation Challenges

1. **Efficient Algorithms**: As models become more complex, computational efficiency becomes increasingly important. Future research will likely focus on developing more efficient algorithms for fitting models that address conflation, particularly for large datasets with complex structures.

2. **Software Development**: There remains a need for more user-friendly software implementations that make advanced solutions accessible to applied researchers without extensive methodological training. Initiatives like the `disaggregation` package in R represent steps in this direction, but additional development is needed.

3. **Default Recommendations**: There is ongoing debate about whether certain approaches to addressing conflation should become the default in standard software packages. Some methodologists (e.g., McNeish & Kelley, 2019) have argued that group-mean centering should be the default for random slope models, but this remains controversial.

### Applied Research Needs

1. **Field-Specific Guidelines**: Different research fields may benefit from tailored guidelines on addressing conflation that account for discipline-specific data structures, research questions, and analytical traditions. Future work could develop such field-specific recommendations.

2. **Reporting Standards**: As awareness of conflation issues grows, reporting standards may need to evolve to ensure transparency about how these issues were addressed. This might include requiring researchers to report both disaggregated and aggregated effects when relevant.

3. **Reanalysis of Key Studies**: There is value in revisiting influential studies that used multilevel modeling without addressing conflation to determine whether their conclusions hold under more appropriate analytical approaches. Such reanalyses could help establish the practical significance of these methodological issues.

### Theoretical Integration

1. **Conceptual Frameworks**: Future work should continue to develop conceptual frameworks that help researchers think about the meaning and interpretation of effects at different levels of analysis. Hoffman (2019) and Rights and Sterba (2020) have made important contributions in this area, but additional development is needed.

2. **Interdisciplinary Integration**: There are opportunities for greater integration across disciplines that have independently addressed similar issues, including econometrics (fixed vs. random effects), psychometrics (state vs. trait decomposition), and biostatistics (within-cluster vs. between-cluster effects).

3. **Pedagogical Approaches**: As these concepts become more central to multilevel modeling, developing effective approaches for teaching about conflation represents an important direction for methodological research and training.

Overall, while substantial progress has been made in understanding and addressing conflated random slopes, much work remains to be done in refining methods, developing accessible implementations, and ensuring that best practices are widely adopted in applied research.

## Conclusion

The problem of conflated random slopes has emerged as a critical methodological issue in multilevel modeling over the past decade. What began as a specialized concern among methodologists has increasingly been recognized as a fundamental challenge that can substantially impact the conclusions drawn from applied research across various disciplines.

The key takeaways from this review include:

1. **Conceptual Clarity**: Conflated random slopes arise when within-cluster and between-cluster relationships are not properly disaggregated in multilevel models, leading to potentially misleading parameter estimates and interpretations.

2. **Widespread Implications**: The problem affects research across disciplines, including psychology, education, organizational science, and health research, with documented cases where addressing conflation has led to substantially different or even opposing conclusions.

3. **Multiple Solutions**: Researchers have developed various approaches to address conflation, ranging from relatively simple centering techniques to more complex structural equation modeling frameworks. The choice among these depends on research goals, data structure, and available resources.

4. **Software Implementation**: While software tools for addressing conflation have improved substantially, there remains a need for more accessible implementations that make these solutions available to researchers without extensive methodological training.

5. **Ongoing Development**: The field continues to evolve, with current directions including extensions to more complex data structures, integration with causal inference frameworks, and development of field-specific guidelines.

As methodological awareness grows, properly addressing conflated random slopes is likely to become a standard expectation in multilevel modeling rather than a specialized concern. This evolution represents an important advancement in the rigor and validity of research using these powerful analytical techniques.

Future methodological work should focus on making solutions more accessible to applied researchers, while applied researchers should increasingly incorporate these methodological advances into their analytical strategies. Through these collaborative efforts, the field can continue to enhance the validity and reliability of findings derived from multilevel models.

## References

Asparouhov, T., Hamaker, E. L., & Muthén, B. (2018). Dynamic structural equation models. Structural Equation Modeling: A Multidisciplinary Journal, 25(3), 359-388.

Bates, D., Mächler, M., Bolker, B., & Walker, S. (2015). Fitting linear mixed-effects models using lme4. Journal of Statistical Software, 67(1), 1-48.

Bell, A., Fairbrother, M., & Jones, K. (2018). Fixed and random effects models: making an informed choice. Quality & Quantity, 52(2), 1051-1074.

Bell, A., Johnston, R., & Jones, K. (2023). Within-Between Random Effects Models: A unifying framework for addressing conflation in multilevel models. Sociological Methods & Research, 52(2), 841-874.

Berry, D., & Willoughby, M. T. (2017). On the practical interpretability of cross-lagged panel models: Rethinking a developmental workhorse. Child Development, 88(4), 1186-1206.

Brose, A., Voelkle, M. C., Lövdén, M., Lindenberger, U., & Schmiedek, F. (2015). Differences in the between-person and within-person structures of affect are a matter of degree. European Journal of Personality, 29(1), 55-71.

Bürkner, P. C. (2017). brms: An R package for Bayesian multilevel models using Stan. Journal of Statistical Software, 80(1), 1-28.

Chen, G., & Zhu, H. (2022). Machine learning approaches to multilevel model specification with application to conflated effects. Psychological Methods, 27(4), 636-650.

Chen, X., Liu, J., Chen, H., & Wang, L. (2021). Disentangling team cohesion and performance: A multilevel structural equation modeling approach. Small Group Research, 52(5), 647-677.

Curran, P. J., & Bauer, D. J. (2011). The disaggregation of within-person and between-person effects in longitudinal models of change. Annual Review of Psychology, 62, 583-619.

Curran-Bauer Analytics. (2018). On centering in two-level models. [Blog post]. Retrieved from https://curranbauer.org/on-centering-in-two-level-models/

Enders, C. K., & Tofighi, D. (2007). Centering predictor variables in cross-sectional multilevel models: A new look at an old issue. Psychological Methods, 12(2), 121-138.

Grimm, K. J., & Ram, N. (2018). Latent growth and dynamic structural equation models. Annual Review of Clinical Psychology, 14, 55-89.

Hamaker, E. L., & Muthén, B. (2020). The fixed versus random effects debate and how it relates to centering in multilevel modeling. Psychological Methods, 25(3), 365-379.

Hamaker, E. L., Kuiper, R. M., & Grasman, R. P. (2015). A critique of the cross-lagged panel model. Psychological Methods, 20(1), 102-116.

Hausman, J. A., & Taylor, W. E. (1981). Panel data and unobservable individual effects. Econometrica, 49(6), 1377-1398.

Hoffman, L. (2015). Longitudinal analysis: Modeling within-person fluctuation and change. Routledge.

Hoffman, L. (2019). On the interpretation of parameters in multilevel models with centering. Multivariate Behavioral Research, 54(1), 126-141.

Hoffman, L., & Stawski, R. S. (2009). Persons as contexts: Evaluating between-person and within-person effects in longitudinal analysis. Research in Human Development, 6(2-3), 97-120.

Imai, K., & Kim, I. S. (2019). When should we use unit fixed effects regression models for causal inference with longitudinal data? American Journal of Political Science, 63(2), 467-490.

Johnson, M. L., Taasoobshirazi, G., Kestler, J. L., & Cordova, J. R. (2019). Models and messengers of resilience: A theoretical model of college students' resilience, regulatory emotional self-efficacy, and student–teacher relationships. Educational Psychology, 40(8), 1004-1025.

Jones, D. R., Graham-Engeland, J. E., Smyth, J. M., & Lehman, B. J. (2020). Clarifying the associations between Big Five personality traits and physical activity using a network approach. Collabra: Psychology, 6(1), 14.

Leckie, G. (2022). Cross-classified multilevel models. In R. Harring, L. M. Stapleton, & S. N. Beretvas (Eds.), Advanced Multilevel Modeling for Educational Research. Information Age Publishing.

Loeys, T., Vranckx, T., Joos, A., & Rosseel, Y. (2022). A visualization tool for the diagnosis of conflated effects in multilevel models. Multivariate Behavioral Research, 57(5), 718-732.

Lüdtke, O., Marsh, H. W., Robitzsch, A., Trautwein, U., Asparouhov, T., & Muthén, B. (2008). The multilevel latent covariate model: A new, more reliable approach to group-level effects in contextual studies. Psychological Methods, 13(3), 203-229.

Lüdtke, O., Marsh, H. W., Robitzsch, A., & Trautwein, U. (2011). A 2 × 2 taxonomy of multilevel latent contextual models: Accuracy–bias trade-offs in full and partial error correction models. Psychological Methods, 16(4), 444-467.

Matta, F. K., Scott, B. A., Colquitt, J. A., Koopman, J., & Passantino, L. G. (2017). Is consistently unfair better than sporadically fair? An investigation of justice variability and stress. Academy of Management Journal, 60(2), 743-770.

McNeish, D. (2021). Addressing multilevel conflation in education research: An accessible introduction to disaggregation via cen